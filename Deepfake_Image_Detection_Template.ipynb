{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCzYWQP3UILh"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.30.2\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install datasets==2.10.1\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install nltk\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install tqdm\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AUdMTFEru65Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "mskuXF9tYOmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up Image Data Generators:"
      ],
      "metadata": {
        "id": "HViw8agOm4UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (128, 128)  # Adjust size as needed\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "KUFfqpBygCGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Data Generators for Training, Testing, and Verification Sets:"
      ],
      "metadata": {
        "id": "q8s1Ts1CnBtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data augmentation for the training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "Lo8RX9fhm9cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For testing and verification, we only rescale\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "ae7wazBcnMPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/AGI House Hackathon Collaborate/Smaller Dataset 100 img per class',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "60wWd_oknH_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/AGI House Hackathon Collaborate/Smaller Dataset 100 img per class/Test',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important for evaluation\n",
        ")"
      ],
      "metadata": {
        "id": "x6C4iWDmnFWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify_generator = test_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/AGI House Hackathon Collaborate/Smaller Dataset 100 img per class/Validation',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important for evaluation\n",
        ")"
      ],
      "metadata": {
        "id": "8niy5Md1nTzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "train_datagen: Includes data augmentation to prevent overfitting.\n",
        "test_datagen: Only rescales the images.\n",
        "flow_from_directory: Automatically assigns labels based on the subdirectory names (fake and real).\n"
      ],
      "metadata": {
        "id": "d0uHEH86nXmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Class Indices:"
      ],
      "metadata": {
        "id": "xtMNppldnaiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print class indices\n",
        "print(\"Class indices: Fake, Real\", train_generator.class_indices)"
      ],
      "metadata": {
        "id": "bWYmLlvMnfku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:\n",
        "Class indices: {'fake': 0, 'real': 1}"
      ],
      "metadata": {
        "id": "BV6Tk0snnn6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Building the Image Detection Model"
      ],
      "metadata": {
        "id": "GqcjurNSn1kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the CNN Model:"
      ],
      "metadata": {
        "id": "Vu8qQ5rUn6zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(*IMAGE_SIZE, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "Ct1KKXGxnbR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Convolutional Layers: Extract features from images.\n",
        "Pooling Layers: Reduce spatial dimensions.\n",
        "Flatten Layer: Flattens the output for the dense layers.\n",
        "Dense Layers: Perform classification.\n",
        "Dropout Layer: Prevents overfitting."
      ],
      "metadata": {
        "id": "6140tIiIn__A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the Model:"
      ],
      "metadata": {
        "id": "PaoS9dvxoLCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "a4E8laJEoNyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Optimizer: Adam optimizer.\n",
        "Loss Function: Binary crossentropy for binary classification.\n",
        "Metrics: Accuracy."
      ],
      "metadata": {
        "id": "xYc50NWYoV3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Training the Model"
      ],
      "metadata": {
        "id": "mm-GUmDZoa_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up Callbacks:"
      ],
      "metadata": {
        "id": "rasxmUwwodpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n"
      ],
      "metadata": {
        "id": "nsm_N2QXogxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model:"
      ],
      "metadata": {
        "id": "Hp5xhvhsooXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10  # Adjust as needed\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "Bd88gvxTopnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Steps per Epoch: Number of batches per epoch.\n",
        "Validation Steps: Number of batches for validation.\n",
        "Callbacks: Early stopping and model checkpointing to save the best model."
      ],
      "metadata": {
        "id": "KQIJAk7Xos-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Training History:"
      ],
      "metadata": {
        "id": "D2T9SJ1Nov3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fit9M286oyOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Evaluating the Model"
      ],
      "metadata": {
        "id": "2y9ycyoFo4hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Best Model:"
      ],
      "metadata": {
        "id": "_C1IOUQyo6VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved model\n",
        "model.load_weights('best_model.h5')"
      ],
      "metadata": {
        "id": "gecutfvio8gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on Test Data"
      ],
      "metadata": {
        "id": "aR36BkGQpI8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "D8wwPptopQ4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on Verify Data:"
      ],
      "metadata": {
        "id": "eFao8zbTpVWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verify_loss, verify_accuracy = model.evaluate(verify_generator, steps=verify_generator.samples // BATCH_SIZE)\n",
        "print(f'Verify Accuracy: {verify_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "ix2bz0WSpZKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Classification Report and Confusion Matrix:"
      ],
      "metadata": {
        "id": "eTUx_o5CpgS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get true labels and predictions for test data\n",
        "test_generator.reset()\n",
        "Y_pred = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)\n",
        "y_pred = np.where(Y_pred > 0.5, 1, 0)\n",
        "\n",
        "y_true = test_generator.classes[:len(y_pred)]\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report')\n",
        "target_names = ['Fake', 'Real']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix - Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ll_B-xnlphhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Testing the Model"
      ],
      "metadata": {
        "id": "gSRHlobVpmTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions on New Images:"
      ],
      "metadata": {
        "id": "ub7eTEmPptgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict and display result\n",
        "def predict_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=IMAGE_SIZE)\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_label = int(prediction[0][0] > 0.5)\n",
        "    confidence = prediction[0][0] if predicted_label == 1 else 1 - prediction[0][0]\n",
        "    label_map = {0: 'Fake', 1: 'Real'}\n",
        "    label = label_map[predicted_label]\n",
        "    print(f\"Predicted Label: {label} with confidence {confidence * 100:.2f}%\")\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8vqMuf3fpoyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test with an Image from the Verify Set:"
      ],
      "metadata": {
        "id": "R-U2RvO_pxQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random image from the verify set\n",
        "import random\n",
        "\n",
        "verify_image_files = []\n",
        "for class_name in ['/content/drive/MyDrive/AGI House Hackathon Collaborate/Smaller Dataset 100 img per class/Validation/Fake', '/content/drive/MyDrive/AGI House Hackathon Collaborate/Smaller Dataset 100 img per class/Validation/Real']:\n",
        "    class_dir = os.path.join('/content/drive/MyDrive/AGI House Hackathon Collaborate/Smaller Dataset 100 img per class/Validation', class_name)\n",
        "    verify_image_files.extend([os.path.join(class_dir, fname) for fname in os.listdir(class_dir)])\n",
        "\n",
        "# Select a random image\n",
        "random_image = random.choice(verify_image_files)\n",
        "print(f\"Actual Label: {random_image.split('/')[-2].capitalize()}\")\n",
        "\n",
        "# Predict and display the image\n",
        "predict_image(random_image)"
      ],
      "metadata": {
        "id": "YZjO3Hz9p1UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test with Your Own Image:"
      ],
      "metadata": {
        "id": "0-ruKrYFp53r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload an image to Colab:"
      ],
      "metadata": {
        "id": "x50ZKoAJp-bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GQmyuf6pqFwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The uploaded file will be in the current directory."
      ],
      "metadata": {
        "id": "rljdytLIqIL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the Uploaded Image:"
      ],
      "metadata": {
        "id": "siI8lVGqqMY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_image = list(uploaded.keys())[0]\n",
        "predict_image(uploaded_image)"
      ],
      "metadata": {
        "id": "oGEqOon5qOkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}